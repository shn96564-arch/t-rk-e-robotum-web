# src/agent_core.py

from .rag_manager import retrieve_knowledge, initialize_rag_system
from .tool_factory import get_llm_pipeline, search_web_tool, generate_response
from config import DEFAULT_MODEL_NAME

# RAG Sistemini BaÅŸlatma (Ä°lk yÃ¼kleme)
initialize_rag_system()

# Temel LLM'i yÃ¼kle
LLM_PIPELINE = get_llm_pipeline(DEFAULT_MODEL_NAME)

def run_agent_workflow(user_prompt):
    """
    KullanÄ±cÄ± sorgusuna gÃ¶re en uygun aksiyonu (LLM, RAG veya Web Arama) seÃ§er.
    """
    
    # 1. PLANLAMA: Aksiyon KararÄ±
    if "kuantum" in user_prompt.lower() or "uzay zaman" in user_prompt.lower() or "Ã§ok zor" in user_prompt.lower():
        action = "EXTERNAL_CONSULT"
    elif "internet ara" in user_prompt.lower() or "gÃ¼ncel" in user_prompt.lower() or "son dakika" in user_prompt.lower():
        action = "WEB_SEARCH"
    elif "mÃ¼fredat" in user_prompt.lower() or "Ã¶zel not" in user_prompt.lower() or "Ã¶dev" in user_prompt.lower():
        action = "RAG_LOOKUP"
    else:
        action = "STANDARD_LLM"
    
    # 2. AKSÄ°YON ALMA (GÄ°ZLÄ° OPERASYON)
    
    if action == "WEB_SEARCH":
        web_info = search_web_tool(user_prompt)
        response_prompt = f"AÅŸaÄŸÄ±daki web sonuÃ§larÄ±nÄ± Ã§ocuÄŸun anlayacaÄŸÄ± dille Ã¶zetle: {web_info}"
        return f"ğŸŒ **[GÃœNCEL BÄ°LGÄ° KULLANILDI]**\n{generate_response(LLM_PIPELINE, response_prompt)}"
        
    elif action == "RAG_LOOKUP":
        rag_info = retrieve_knowledge(user_prompt)
        response_prompt = f"Ã–zel notlardan gelen bu bilgiyi kullanarak soruyu cevapla: {rag_info}"
        return f"âœ… **[DERS NOTU KULLANILDI]**\n{generate_response(LLM_PIPELINE, response_prompt)}"
        
    elif action == "EXTERNAL_CONSULT":
        # SimÃ¼lasyon: Grok/Gemini'den yanÄ±t alÄ±ndÄ±
        return "ğŸ”„ **[GÄ°ZLÄ° KARDEÅ KULLANILDI]** Zor soru, Grok/Gemini tarafÄ±ndan onaylandÄ±: Kuantum dÃ¼nyasÄ±, olasÄ±lÄ±klarla yÃ¶netilen ve klasik fiziÄŸe meydan okuyan bir alandÄ±r."
        
    else:
        # Standart LLM ile yanÄ±t Ã¼retme
        return f"ğŸ§  **[ANA BEYÄ°N KULLANILDI]**\n{generate_response(LLM_PIPELINE, user_prompt)}"